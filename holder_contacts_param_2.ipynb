{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 22:37:06.563545: W external/xla/xla/service/gpu/nvptx_compiler.cc:930] The NVIDIA driver's CUDA version is 12.4 which is older than the PTX compiler version 12.6.77. Because the driver is older than the PTX compiler version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax.example_libraries import stax, optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "import pyvista as pv\n",
    "import pinns \n",
    "import datetime\n",
    "import jax.scipy.optimize\n",
    "import jax.flatten_util\n",
    "import scipy\n",
    "import scipy.optimize\n",
    "import random\n",
    "\n",
    "rnd_key = jax.random.PRNGKey(1234)\n",
    "np.random.seed(14124)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the default precision and the execution device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Devices:  [CudaDevice(id=0)]\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "jax.config.update(\"jax_enable_x64\", False)\n",
    "print(\"Devices: \", jax.devices())\n",
    "dev = jax.devices('gpu')[0] if jax.device_count()>1 and len(jax.devices('gpu'))>0 else jax.devices('cpu')[0]\n",
    "dev = jax.devices('gpu')[0]\n",
    "print(dev)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geometry definition \n",
    "\n",
    "Define the geometry patches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_domain(r0: float, r1: float, R: float, h: float, H: float):\n",
    "\n",
    "    angle = np.pi/4\n",
    "    basis1 = pinns.functions.BSplineBasisJAX(np.array([-1, 0, 1]), 2)\n",
    "    basis2 = pinns.functions.BSplineBasisJAX(np.array([-1, 1]), 2)\n",
    "    basis3 = pinns.functions.BSplineBasisJAX(np.array([-1, 1]), 1)\n",
    "\n",
    "    def tmp_gen(angle, r_0, r_1):\n",
    "        pts = np.zeros([4, 3, 2, 3])\n",
    "        weights = np.ones([4, 3, 2])\n",
    "\n",
    "        a = np.pi/2-angle/2\n",
    "        rs = np.linspace(r_0, r_1, 4)\n",
    "        pts[-1, 0, 0, :] = [np.cos(-angle/2), np.sin(-angle/2), 0]\n",
    "        pts[-1, 1, 0, :] = [1/np.sin(a), 0, 0]\n",
    "        pts[-1, 2, 0, :] = [np.cos(angle/2), np.sin(angle/2), 0]\n",
    "        pts[0, :, 0, :2] = rs[0] * pts[-1, :, 0, :2]\n",
    "        pts[1, :, 0, :2] = rs[1] * pts[-1, :, 0, :2]\n",
    "        pts[2, :, 0, :2] = rs[2] * pts[-1, :, 0, :2]\n",
    "        pts[3, :, 0, :2] = rs[3] * pts[-1, :, 0, :2]\n",
    "        pts[0, :, 0, 2] = -1\n",
    "        pts[1, :, 0, 2] = -1\n",
    "        pts[2, :, 0, 2] = -1\n",
    "        pts[3, :, 0, 2] = -1\n",
    "        pts[:, :, 1, :] = pts[:, :, 0, :]\n",
    "        pts[:, :, 1, 2] = -pts[:, :, 1, 2]\n",
    "        weights[:, 1, :] = np.sin(a)\n",
    "\n",
    "        return pts, weights\n",
    "\n",
    "    geoms = dict()\n",
    "\n",
    "    pts, weights = tmp_gen(angle, r0, r1)\n",
    "    pts[:, :, :, 2] *= h/2\n",
    "    # pts[2:,:,:,2] *= h/2\n",
    "    pts[3, 1, :, 0] = pts[3, 0, :, 0]\n",
    "    pts[1, 1, :, 0] = 2*pts[0, 1, :, 0]/3+pts[-1, 1, :, 0]/3\n",
    "    pts[2, 1, :, 0] = pts[0, 1, :, 0]/3+2*pts[-1, 1, :, 0]/3\n",
    "    weights[-1, 1, :] = 1.0\n",
    "\n",
    "    geoms['flat'] = pinns.geometry.PatchNURBS(\n",
    "        [basis1, basis2, basis3], pts.copy(), weights.copy(), 0, 3)\n",
    "\n",
    "    pts2 = pts[-1, :, :, :]\n",
    "    weights[...] = 1.0\n",
    "    linsp = np.linspace(0, 1, basis1.n)\n",
    "\n",
    "    pts[0, :, :, :] = pts2\n",
    "    pts[-1, :, :, :] = pts2\n",
    "    pts[-1, :, :, 0] *= R/r1\n",
    "    pts[-1, :, :, 1] *= H/h\n",
    "    # pts[0, :, :, 2] *= H/h\n",
    "\n",
    "    for i in range(1, basis1.n-1):\n",
    "        pts[i, :, :, 2] = (1-linsp[i]**0.25)*pts[0, :, :, 2] + \\\n",
    "            linsp[i]**0.25*pts[-1, :, :, 2]\n",
    "        pts[i, :, :, 0] = (1-linsp[i])*pts[0, :, :, 0] + \\\n",
    "            linsp[i]*pts[-1, :, :, 0]\n",
    "        pts[i, :, :, 1] = (1-linsp[i]**4)*pts[0, :, :, 1] + \\\n",
    "            linsp[i]**4*pts[-1, :, :, 1]\n",
    "        pts[i, :, :, 1] *= 2*(linsp[i]-1/2)**2+0.5\n",
    "        pts[i, :, :, 2] *= 2*(linsp[i]-1/2)**2+0.5\n",
    "\n",
    "    geoms['spoke'] = pinns.geometry.PatchNURBS(\n",
    "        [basis1, basis2, basis3], pts, weights, 0, 3)\n",
    "\n",
    "    pts, weights = tmp_gen((2*np.pi-angle)/3, r0, r1)\n",
    "    pts[:, :, :, 2] *= h/2\n",
    "    # pts[2:,:,:,2] *= h/2\n",
    "\n",
    "    geoms['round_0'] = pinns.geometry.PatchNURBS(\n",
    "        [basis1, basis2, basis3], pts, weights, 0, 3)\n",
    "    geoms['round_0'].rotate((0, 0, angle/2 + (2*np.pi-angle)/3/2))\n",
    "\n",
    "    pts, weights = tmp_gen((2*np.pi-angle)/3, r0, r1)\n",
    "    pts[:, :, :, 2] *= h/2\n",
    "    # pts[2:,:,:,2] *= h/2\n",
    "\n",
    "    geoms['round_1'] = pinns.geometry.PatchNURBS(\n",
    "        [basis1, basis2, basis3], pts, weights, 0, 3)\n",
    "    geoms['round_1'].rotate((0, 0, np.pi))\n",
    "\n",
    "    pts, weights = tmp_gen((2*np.pi-angle)/3, r0, r1)\n",
    "    pts[:, :, :, 2] *= h/2\n",
    "    # pts[2:,:,:,2] *= h/2\n",
    "\n",
    "    geoms['round_2'] = pinns.geometry.PatchNURBS(\n",
    "        [basis1, basis2, basis3], pts, weights, 0, 3)\n",
    "    geoms['round_2'].rotate((0, 0, (2*np.pi-angle)/3 + np.pi))\n",
    "\n",
    "    return geoms\n",
    "\n",
    "\n",
    "geoms = get_domain(0.5, 0.8, 3.0, 1.0, 1.5)\n",
    "names = list(geoms.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export as a VTK file for visualization in paraview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with jax.disable_jit():\n",
    "    objects = [pinns.extras.plot(geoms[n], dict(), N=32) for n in geoms]\n",
    "\n",
    "obj = objects[0]\n",
    "for i in range(1, len(objects)):\n",
    "    obj = obj.merge(objects[i])\n",
    "\n",
    "obj.save('testing.vtk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the connectivity of the patches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'first': 'flat', 'second': 'spoke', 'axis_first': (0,), 'axis_second': (0,), 'end_first': (-1,), 'end_second': (0,), 'axis_permutation': (None, (1, 1), (2, 1))}\n",
      "{'first': 'flat', 'second': 'round_0', 'axis_first': (1,), 'axis_second': (1,), 'end_first': (-1,), 'end_second': (0,), 'axis_permutation': ((0, 1), None, (2, 1))}\n",
      "{'first': 'flat', 'second': 'round_2', 'axis_first': (1,), 'axis_second': (1,), 'end_first': (0,), 'end_second': (-1,), 'axis_permutation': ((0, 1), None, (2, 1))}\n",
      "{'first': 'spoke', 'second': 'round_0', 'axis_first': (0, 1), 'axis_second': (0, 1), 'end_first': (0, -1), 'end_second': (-1, 0), 'axis_permutation': (None, None, (2, 1))}\n",
      "{'first': 'spoke', 'second': 'round_2', 'axis_first': (0, 1), 'axis_second': (0, 1), 'end_first': (0, 0), 'end_second': (-1, -1), 'axis_permutation': (None, None, (2, 1))}\n",
      "{'first': 'round_0', 'second': 'round_1', 'axis_first': (1,), 'axis_second': (1,), 'end_first': (-1,), 'end_second': (0,), 'axis_permutation': ((0, 1), None, (2, 1))}\n",
      "{'first': 'round_1', 'second': 'round_2', 'axis_first': (1,), 'axis_second': (1,), 'end_first': (-1,), 'end_second': (0,), 'axis_permutation': ((0, 1), None, (2, 1))}\n"
     ]
    }
   ],
   "source": [
    "with jax.disable_jit(True):\n",
    "    connectivity = pinns.geometry.match_patches(geoms, eps=1e-4, verbose=False)\n",
    "\n",
    "for c in connectivity:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in geoms:\n",
    "    pinns.geometry.save_patch('holder_'+k+'.geom', geoms[k])\n",
    "\n",
    "import pickle \n",
    "\n",
    "with open('connectivity_holder.pkl', 'wb') as file: \n",
    "    pickle.dump(connectivity, file) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN spaces definition\n",
    "\n",
    "The network is an MLP with residual connections and width set by the `nl` paraemter.\n",
    "There are 2 spaces defined: first has 0 Dirichlet BCs on one facet and the other has no Dirichlet BCs enforced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = 16\n",
    "acti =  stax.elementwise(lambda x: jax.nn.leaky_relu(x)**2)\n",
    "w_init = jax.nn.initializers.normal()\n",
    "\n",
    "#block_first = stax.serial(stax.FanOut(2),stax.parallel(stax.serial(stax.Dense(nl,W_init = w_init), acti, stax.Dense(nl,W_init = w_init), acti),stax.Dense(nl,W_init = w_init)),stax.FanInSum)\n",
    "#block = stax.serial(stax.FanOut(2),stax.parallel(stax.serial(stax.Dense(nl,W_init = w_init), acti, stax.Dense(nl,W_init = w_init), acti),stax.Dense(nl,W_init = w_init)),stax.FanInSum)\n",
    "block_first = lambda nl: stax.serial(stax.FanInConcat(),stax.Dense(nl, W_init = w_init,b_init=jax.nn.initializers.zeros),acti)\n",
    "block = lambda nl: stax.serial(stax.FanOut(2),stax.parallel(stax.serial(stax.Dense(nl,W_init = w_init), acti, stax.Dense(nl,W_init = w_init), acti),stax.Dense(nl,W_init = w_init)),stax.FanInSum)\n",
    "        \n",
    "nn_3d = stax.serial(block_first(n_layers), block(n_layers), block(n_layers), stax.Dense(3))\n",
    "nn_2d = stax.serial(block_first(16), block(16), block(16), stax.Dense(3))\n",
    "nn_1d = stax.serial(block_first(16), block(16), block(16), stax.Dense(3))\n",
    "\n",
    "def monom(x, axis, zero, one, alpha=1.0):\n",
    "    return ((x[...,axis]-zero)[...,None]/(one-zero))**alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PINNs\n",
    "\n",
    "Define the PINN class. The loss has to be defined. In this case, the nonlinear geometry is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pinn(pinns.PINN):\n",
    "    \n",
    "    def __init__(self):\n",
    "          \n",
    "        NP = 2\n",
    "        input_shape = ((-1,3), (-1,NP))\n",
    "        names_nn_2d = [\"flat_spoke\", \"flat_round_0\", \"flat_round_2\", \"round_0_round_1\", \"round_1_round_2\"]\n",
    "        names_nn_1d = [\"spoke_round_0_flat\", \"spoke_round_2_flat\"]\n",
    "        self.weights = {n: nn_3d[0](rnd_key, ((-1,3),(-1,NP)))[1] for n in names}\n",
    "        self.weights.update({n: nn_2d[0](rnd_key, ((-1,2),(-1,NP)))[1] for n in names_nn_2d})\n",
    "        self.weights.update({n: nn_1d[0](rnd_key, ((-1,1),(-1,NP)))[1] for n in names_nn_1d})\n",
    "        #self.solutions = pinns.connectivity_to_interfaces({n: space_bc if 'spoke' in n else space for n in names}, connectivity, decay_fun=lambda x: x**2)\n",
    "    \n",
    "        self.solutions = {\n",
    "            \"spoke\": lambda ws, x, p: nn_3d[1](ws[\"spoke\"], (x, p))*monom(x, 0, -1, 1)*monom(x, 0, 1, -1)\n",
    "                                    + nn_2d[1](ws[\"flat_spoke\"], (x[...,1:3], p))*monom(x, 0, 1, -1)*monom(x, 1, 1, -1)*monom(x, 1, -1, 1)\n",
    "                                    + nn_1d[1](ws[\"spoke_round_0_flat\"], (x[...,2][...,None], p))*monom(x, 0, 1, -1)*monom(x, 1, -1, 1)\n",
    "                                    + nn_1d[1](ws[\"spoke_round_2_flat\"], (x[...,2][...,None], p))*monom(x, 0, 1, -1)*monom(x, 1, 1, -1),\n",
    "                                    \n",
    "            \"flat\": lambda ws, x, p: nn_3d[1](ws[\"flat\"], (x, p))*monom(x, 0, 1, -1)*monom(x, 1, 1, -1)*monom(x, 1, -1, 1)\n",
    "                                    + nn_2d[1](ws[\"flat_spoke\"], (x[...,1:3], p))*monom(x, 0, -1, 1)*monom(x, 1, 1, -1)*monom(x, 1, -1, 1)\n",
    "                                    + nn_2d[1](ws[\"flat_round_0\"], (x[...,0:3:2], p))*monom(x, 0, 1, -1)*monom(x, 1, -1, 1)\n",
    "                                    + nn_2d[1](ws[\"flat_round_2\"], (x[...,0:3:2], p))*monom(x, 0, 1, -1)*monom(x, 1, 1, -1)\n",
    "                                    + nn_1d[1](ws[\"spoke_round_0_flat\"], (x[...,2][...,None], p))*monom(x, 0, -1, 1)*monom(x, 1, -1, 1)\n",
    "                                    + nn_1d[1](ws[\"spoke_round_2_flat\"], (x[...,2][...,None], p))*monom(x, 0, -1, 1)*monom(x, 1, 1, -1),\n",
    "                                    \n",
    "            \"round_0\": lambda ws, x, p: nn_3d[1](ws[\"round_0\"], (x, p))*monom(x, 1, -1, 1)*monom(x, 1, 1, -1)\n",
    "                                    + nn_2d[1](ws[\"round_0_round_1\"], (x[...,0:3:2], p))*monom(x, 1, -1, 1)\n",
    "                                    + nn_2d[1](ws[\"flat_round_0\"], (x[...,0:3:2], p))*monom(x, 0, 1, -1)*monom(x, 1, 1, -1)\n",
    "                                    + nn_1d[1](ws[\"spoke_round_0_flat\"], (x[...,2][...,None], p))*monom(x, 0, -1, 1)*monom(x, 1, 1, -1),\n",
    "                                    \n",
    "            \"round_1\": lambda ws, x, p: nn_3d[1](ws[\"round_1\"], (x, p))*monom(x, 1, -1, 1)*monom(x, 1, 1, -1)\n",
    "                                    + nn_2d[1](ws[\"round_0_round_1\"], (x[...,0:3:2], p))*monom(x, 1, 1, -1)\n",
    "                                    + nn_2d[1](ws[\"round_1_round_2\"], (x[...,0:3:2], p))*monom(x, 1, -1, 1),\n",
    "                                    \n",
    "            \"round_2\": lambda ws, x, p: nn_3d[1](ws[\"round_2\"], (x, p))*monom(x, 1, -1, 1)*monom(x, 1, 1, -1)\n",
    "                                    + nn_1d[1](ws[\"spoke_round_2_flat\"], (x[...,2][...,None], p))*monom(x, 0, -1, 1)*monom(x, 1, -1, 1)\n",
    "                                    + nn_2d[1](ws[\"round_1_round_2\"], (x[...,0:3:2], p))*monom(x, 1, 1, -1)\n",
    "                                    + nn_2d[1](ws[\"flat_round_2\"], (x[...,0:3:2], p))*monom(x, 0, 1, -1)*monom(x, 1, -1, 1)\n",
    "        }\n",
    "        \n",
    "        E = 0.02e5\n",
    "        nu = 0.3\n",
    "        self.E = E\n",
    "        self.nu = nu\n",
    "        \n",
    "        self.lamda = E*nu/(1+nu)/(1-2*nu)\n",
    "        self.mu = E/2/(1+nu)\n",
    "\n",
    "        rho = 0.0\n",
    "        g = 9.81\n",
    "        self.rho = rho\n",
    "        \n",
    "        self.f = np.array([0,-g*rho,0]) \n",
    "        self.energy = lambda F,C,J,params: params[0]*jnp.sum(F**2, axis=(-2,-1)) + params[1]*jnp.abs(J)**2*jnp.sum(jnp.linalg.inv(F)**2, axis=(-1,-2)) + params[2]*J**2 - params[3]*jnp.log(jnp.abs(J))+params[4]\n",
    "        self.energy = lambda F,C,J,params: 0.5*self.mu*(C[...,0,0]+C[...,1,1]+C[...,2,2]-3)-self.mu*jnp.log(jnp.abs(J))+0.5*self.lamda*jnp.log(jnp.abs(J))**2\n",
    "        self.energy = lambda F,E,J,params: 0.5*self.lamda*(E[...,0,0]+E[...,1,1]+E[...,2,2])**2+self.mu*jnp.sum(E*E, axis=(-1,-2))\n",
    "        #self.energy = lambda F,E,J,params: 0.5*self.lamda*(E[...,0,0]+E[...,1,1]+E[...,2,2])**2+self.mu*(E[...,0,0]**2+E[...,1,1]**2+E[...,2,2]**2)\n",
    "        \n",
    "        self.a = 0.5*self.mu\n",
    "        self.b = 0.0\n",
    "        self.c = 0.0\n",
    "        self.d = self.mu\n",
    "        self.e = -1.5*self.mu\n",
    "\n",
    "        self.kpen = 8e3\n",
    "        self.Ab = np.array([[0.0,1.0,0.0]]), np.array([[-0.75]]), np.array([[0.0,-1.0,0.0]]), np.array([[-0.75]])\n",
    "        super(Pinn, self).__init__(geoms)\n",
    "   \n",
    "    def solution_flat(ws, x, p):\n",
    "        \n",
    "        return nn_3d[1](ws[\"flat\"], (x, p))\n",
    " \n",
    "    def loss(self, training_parameters, points, parameters):\n",
    "        \n",
    "        jacs = [pinns.functions.jacobian(lambda x, p: self.solutions[n](training_parameters, x, p))(points[n].points_reference, parameters) for n in names]\n",
    "        jacs_x = [points[names[i]].jacobian_transformation(jacs[i]) for i in range(len(names))]\n",
    "        Fs = [jnp.eye(3)+jacs_x[i] for i in range(len(names))]\n",
    "        Cs = [jnp.einsum('mji,mki->mjk', Fs[i], Fs[i]) for i in range(len(names))]\n",
    "        Cs = [0.5*(Cs[i]-jnp.eye(3)[None,...]) for i in range(len(names))]\n",
    "        \n",
    "        dets = [jnp.linalg.det(Fs[i]) for i in range(len(names))]\n",
    "         \n",
    "        Es = [jnp.dot(self.energy(Fs[i], Cs[i], dets[i], [self.a, self.b,self.c,self.d,self.e]), points[names[i]].dx()) for i in range(len(names))]\n",
    "        rhss = [jnp.dot(dets[i] * jnp.einsum('k,mk->m', self.f, self.solutions[names[i]](training_parameters, points[names[i]].points_reference, parameters)), points[names[i]].dx()) for i in range(len(names))] \n",
    "\n",
    "        contact_res  = jnp.dot(pinns.geometry.gap_to_convex_polytope(self.Ab[0], self.Ab[1], jnp.einsum('i,j->ij', parameters[:,0]*0.1/2, np.array([0,1,0])) + points['ds2'].points_physical+self.solutions['round_2'](training_parameters, points['ds2'].points_reference, parameters))**2, points['ds2'].weights)\n",
    "        contact_res += jnp.dot(pinns.geometry.gap_to_convex_polytope(self.Ab[2], self.Ab[3], jnp.einsum('i,j->ij', parameters[:,1]*0.1/2, np.array([0,-1,0])) + points['ds0'].points_physical+self.solutions['round_0'](training_parameters, points['ds0'].points_reference, parameters))**2, points['ds0'].weights)\n",
    "        \n",
    "        return sum(Es) - sum(rhss) + self.kpen * contact_res \n",
    "        \n",
    "model = Pinn()  \n",
    "weights = model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 - mean loss 5.282067e+00, max loss 5.464190e+01, min loss 1.150193e+00, std loss 8.792472e+00\n",
      "Epoch 2/100 - mean loss 8.919865e-01, max loss 1.145700e+00, min loss 7.655606e-01, std loss 9.466783e-02\n",
      "Epoch 3/100 - mean loss 7.236087e-01, max loss 7.661083e-01, min loss 6.891446e-01, std loss 2.046204e-02\n",
      "Epoch 4/100 - mean loss 6.664211e-01, max loss 6.952154e-01, min loss 6.399219e-01, std loss 1.429934e-02\n",
      "Epoch 5/100 - mean loss 6.281891e-01, max loss 6.480744e-01, min loss 6.044011e-01, std loss 1.122389e-02\n",
      "Epoch 6/100 - mean loss 5.972626e-01, max loss 6.128936e-01, min loss 5.803076e-01, std loss 7.621168e-03\n",
      "Epoch 7/100 - mean loss 5.755146e-01, max loss 5.892974e-01, min loss 5.603656e-01, std loss 5.895291e-03\n",
      "Epoch 8/100 - mean loss 5.623964e-01, max loss 5.741163e-01, min loss 5.485646e-01, std loss 5.472261e-03\n",
      "Epoch 9/100 - mean loss 5.545377e-01, max loss 5.631948e-01, min loss 5.426826e-01, std loss 3.994962e-03\n",
      "Epoch 10/100 - mean loss 5.498816e-01, max loss 5.587057e-01, min loss 5.372545e-01, std loss 4.243514e-03\n",
      "Epoch 11/100 - mean loss 5.453998e-01, max loss 5.572453e-01, min loss 5.329996e-01, std loss 4.385784e-03\n",
      "Epoch 12/100 - mean loss 5.423160e-01, max loss 5.531525e-01, min loss 5.295843e-01, std loss 4.132249e-03\n",
      "Epoch 13/100 - mean loss 5.392911e-01, max loss 5.481866e-01, min loss 5.267272e-01, std loss 3.838103e-03\n",
      "Epoch 14/100 - mean loss 5.365996e-01, max loss 5.463477e-01, min loss 5.268374e-01, std loss 4.279269e-03\n",
      "Epoch 15/100 - mean loss 5.322877e-01, max loss 5.428995e-01, min loss 5.195525e-01, std loss 4.296259e-03\n",
      "Epoch 16/100 - mean loss 5.306501e-01, max loss 5.426730e-01, min loss 5.173615e-01, std loss 4.390527e-03\n",
      "Epoch 17/100 - mean loss 5.287746e-01, max loss 5.417292e-01, min loss 5.163400e-01, std loss 4.158902e-03\n",
      "Epoch 18/100 - mean loss 5.279913e-01, max loss 5.371702e-01, min loss 5.191392e-01, std loss 3.851036e-03\n",
      "Epoch 19/100 - mean loss 5.266049e-01, max loss 5.356694e-01, min loss 5.155492e-01, std loss 4.101518e-03\n",
      "Epoch 20/100 - mean loss 5.248359e-01, max loss 5.364036e-01, min loss 5.125563e-01, std loss 4.622035e-03\n",
      "Epoch 21/100 - mean loss 5.214009e-01, max loss 5.328182e-01, min loss 5.083372e-01, std loss 4.545209e-03\n",
      "Epoch 22/100 - mean loss 5.172331e-01, max loss 5.252232e-01, min loss 5.064353e-01, std loss 3.657366e-03\n",
      "Epoch 23/100 - mean loss 5.166206e-01, max loss 5.254160e-01, min loss 5.056534e-01, std loss 3.653726e-03\n",
      "Epoch 24/100 - mean loss 5.160317e-01, max loss 5.245704e-01, min loss 5.052023e-01, std loss 3.641820e-03\n",
      "Epoch 25/100 - mean loss 5.148257e-01, max loss 5.230386e-01, min loss 5.046470e-01, std loss 3.660601e-03\n",
      "Epoch 26/100 - mean loss 5.140306e-01, max loss 5.223916e-01, min loss 5.030670e-01, std loss 3.631636e-03\n",
      "Epoch 27/100 - mean loss 5.136049e-01, max loss 5.213803e-01, min loss 5.024259e-01, std loss 3.642036e-03\n",
      "Epoch 28/100 - mean loss 5.132410e-01, max loss 5.210214e-01, min loss 5.022686e-01, std loss 3.654112e-03\n",
      "Epoch 29/100 - mean loss 5.128339e-01, max loss 5.208336e-01, min loss 5.019423e-01, std loss 3.639546e-03\n",
      "Epoch 30/100 - mean loss 5.124938e-01, max loss 5.206588e-01, min loss 5.013428e-01, std loss 3.684408e-03\n",
      "Epoch 31/100 - mean loss 5.120008e-01, max loss 5.198736e-01, min loss 5.010806e-01, std loss 3.608535e-03\n",
      "Epoch 32/100 - mean loss 5.119205e-01, max loss 5.192024e-01, min loss 5.013618e-01, std loss 3.573987e-03\n",
      "Epoch 33/100 - mean loss 5.121247e-01, max loss 5.221450e-01, min loss 5.011905e-01, std loss 3.691307e-03\n",
      "Epoch 34/100 - mean loss 5.119048e-01, max loss 5.209194e-01, min loss 5.007516e-01, std loss 3.834495e-03\n",
      "Epoch 35/100 - mean loss 5.118683e-01, max loss 5.197690e-01, min loss 5.013767e-01, std loss 3.752155e-03\n",
      "Epoch 36/100 - mean loss 5.113935e-01, max loss 5.188707e-01, min loss 5.004996e-01, std loss 3.865315e-03\n",
      "Epoch 37/100 - mean loss 5.118448e-01, max loss 5.219027e-01, min loss 4.993342e-01, std loss 3.950708e-03\n",
      "Epoch 38/100 - mean loss 5.112219e-01, max loss 5.177639e-01, min loss 5.009295e-01, std loss 3.719173e-03\n",
      "Epoch 39/100 - mean loss 5.105600e-01, max loss 5.203770e-01, min loss 5.017813e-01, std loss 3.618475e-03\n",
      "Epoch 40/100 - mean loss 5.109365e-01, max loss 5.270571e-01, min loss 5.001040e-01, std loss 4.150101e-03\n",
      "Epoch 41/100 - mean loss 5.105317e-01, max loss 5.180766e-01, min loss 4.990717e-01, std loss 4.201392e-03\n",
      "Epoch 42/100 - mean loss 5.079643e-01, max loss 5.157374e-01, min loss 4.970046e-01, std loss 3.656095e-03\n",
      "Epoch 43/100 - mean loss 5.077739e-01, max loss 5.155167e-01, min loss 4.969590e-01, std loss 3.644928e-03\n",
      "Epoch 44/100 - mean loss 5.076320e-01, max loss 5.155725e-01, min loss 4.968118e-01, std loss 3.647647e-03\n",
      "Epoch 45/100 - mean loss 5.075334e-01, max loss 5.155472e-01, min loss 4.967169e-01, std loss 3.644180e-03\n",
      "Epoch 46/100 - mean loss 5.074020e-01, max loss 5.153740e-01, min loss 4.967663e-01, std loss 3.625735e-03\n",
      "Epoch 47/100 - mean loss 5.073562e-01, max loss 5.152813e-01, min loss 4.963798e-01, std loss 3.674711e-03\n",
      "Epoch 48/100 - mean loss 5.071517e-01, max loss 5.150198e-01, min loss 4.963245e-01, std loss 3.656898e-03\n",
      "Epoch 49/100 - mean loss 5.071051e-01, max loss 5.149256e-01, min loss 4.961031e-01, std loss 3.637470e-03\n",
      "Epoch 50/100 - mean loss 5.070059e-01, max loss 5.147810e-01, min loss 4.962366e-01, std loss 3.641092e-03\n",
      "Epoch 51/100 - mean loss 5.068033e-01, max loss 5.145524e-01, min loss 4.957553e-01, std loss 3.658686e-03\n",
      "Epoch 52/100 - mean loss 5.068153e-01, max loss 5.146311e-01, min loss 4.959673e-01, std loss 3.609912e-03\n",
      "Epoch 53/100 - mean loss 5.066763e-01, max loss 5.148501e-01, min loss 4.956261e-01, std loss 3.644909e-03\n",
      "Epoch 54/100 - mean loss 5.068269e-01, max loss 5.142734e-01, min loss 4.958211e-01, std loss 3.775551e-03\n",
      "Epoch 55/100 - mean loss 5.070345e-01, max loss 5.144129e-01, min loss 4.960057e-01, std loss 3.652807e-03\n",
      "Epoch 56/100 - mean loss 5.066134e-01, max loss 5.140078e-01, min loss 4.961815e-01, std loss 3.628875e-03\n",
      "Epoch 57/100 - mean loss 5.067545e-01, max loss 5.158187e-01, min loss 4.956636e-01, std loss 3.825988e-03\n",
      "Epoch 58/100 - mean loss 5.065554e-01, max loss 5.137910e-01, min loss 4.960125e-01, std loss 3.651751e-03\n",
      "Epoch 59/100 - mean loss 5.065606e-01, max loss 5.147045e-01, min loss 4.959528e-01, std loss 3.689311e-03\n",
      "Epoch 60/100 - mean loss 5.064830e-01, max loss 5.144076e-01, min loss 4.966625e-01, std loss 3.636896e-03\n",
      "Epoch 61/100 - mean loss 5.063523e-01, max loss 5.141643e-01, min loss 4.952723e-01, std loss 3.654193e-03\n",
      "Epoch 62/100 - mean loss 5.050901e-01, max loss 5.128508e-01, min loss 4.942837e-01, std loss 3.630427e-03\n",
      "Epoch 63/100 - mean loss 5.050210e-01, max loss 5.127596e-01, min loss 4.940743e-01, std loss 3.626752e-03\n",
      "Epoch 64/100 - mean loss 5.049706e-01, max loss 5.127082e-01, min loss 4.941120e-01, std loss 3.638715e-03\n",
      "Epoch 65/100 - mean loss 5.048966e-01, max loss 5.125780e-01, min loss 4.939800e-01, std loss 3.620977e-03\n",
      "Epoch 66/100 - mean loss 5.048290e-01, max loss 5.125412e-01, min loss 4.941112e-01, std loss 3.647685e-03\n",
      "Epoch 67/100 - mean loss 5.047806e-01, max loss 5.125088e-01, min loss 4.938114e-01, std loss 3.648628e-03\n",
      "Epoch 68/100 - mean loss 5.046032e-01, max loss 5.123540e-01, min loss 4.938767e-01, std loss 3.621659e-03\n",
      "Epoch 69/100 - mean loss 5.044687e-01, max loss 5.120583e-01, min loss 4.937733e-01, std loss 3.618056e-03\n",
      "Epoch 70/100 - mean loss 5.044427e-01, max loss 5.120865e-01, min loss 4.935113e-01, std loss 3.621625e-03\n",
      "Epoch 71/100 - mean loss 5.042773e-01, max loss 5.120980e-01, min loss 4.934802e-01, std loss 3.638738e-03\n",
      "Epoch 72/100 - mean loss 5.042528e-01, max loss 5.120618e-01, min loss 4.933464e-01, std loss 3.619706e-03\n",
      "Epoch 73/100 - mean loss 5.042281e-01, max loss 5.118526e-01, min loss 4.932372e-01, std loss 3.641828e-03\n",
      "Epoch 74/100 - mean loss 5.041184e-01, max loss 5.117005e-01, min loss 4.933558e-01, std loss 3.601391e-03\n",
      "Epoch 75/100 - mean loss 5.041456e-01, max loss 5.119486e-01, min loss 4.933549e-01, std loss 3.631636e-03\n",
      "Epoch 76/100 - mean loss 5.040808e-01, max loss 5.118047e-01, min loss 4.933694e-01, std loss 3.608712e-03\n",
      "Epoch 77/100 - mean loss 5.039789e-01, max loss 5.116726e-01, min loss 4.929239e-01, std loss 3.660660e-03\n",
      "Epoch 78/100 - mean loss 5.039956e-01, max loss 5.118887e-01, min loss 4.930248e-01, std loss 3.647619e-03\n",
      "Epoch 79/100 - mean loss 5.040756e-01, max loss 5.116519e-01, min loss 4.927545e-01, std loss 3.650510e-03\n",
      "Epoch 80/100 - mean loss 5.040404e-01, max loss 5.116750e-01, min loss 4.944991e-01, std loss 3.626619e-03\n",
      "Epoch 81/100 - mean loss 5.038071e-01, max loss 5.118880e-01, min loss 4.928111e-01, std loss 3.674147e-03\n",
      "Epoch 82/100 - mean loss 5.033288e-01, max loss 5.110616e-01, min loss 4.925072e-01, std loss 3.629176e-03\n",
      "Epoch 83/100 - mean loss 5.032844e-01, max loss 5.110197e-01, min loss 4.924389e-01, std loss 3.629677e-03\n",
      "Epoch 84/100 - mean loss 5.032858e-01, max loss 5.110310e-01, min loss 4.925504e-01, std loss 3.641279e-03\n",
      "Epoch 85/100 - mean loss 5.032216e-01, max loss 5.108649e-01, min loss 4.923185e-01, std loss 3.635620e-03\n",
      "Epoch 86/100 - mean loss 5.031744e-01, max loss 5.108492e-01, min loss 4.922257e-01, std loss 3.617498e-03\n",
      "Epoch 87/100 - mean loss 5.031770e-01, max loss 5.109615e-01, min loss 4.925022e-01, std loss 3.622700e-03\n",
      "Epoch 88/100 - mean loss 5.031145e-01, max loss 5.108821e-01, min loss 4.924240e-01, std loss 3.630939e-03\n",
      "Epoch 89/100 - mean loss 5.030774e-01, max loss 5.107467e-01, min loss 4.921449e-01, std loss 3.620698e-03\n",
      "Epoch 90/100 - mean loss 5.030698e-01, max loss 5.107384e-01, min loss 4.924004e-01, std loss 3.620993e-03\n",
      "Epoch 91/100 - mean loss 5.030529e-01, max loss 5.106387e-01, min loss 4.922244e-01, std loss 3.627210e-03\n",
      "Epoch 92/100 - mean loss 5.030025e-01, max loss 5.107958e-01, min loss 4.921961e-01, std loss 3.632481e-03\n",
      "Epoch 93/100 - mean loss 5.029862e-01, max loss 5.106571e-01, min loss 4.921434e-01, std loss 3.633020e-03\n",
      "Epoch 94/100 - mean loss 5.028858e-01, max loss 5.107780e-01, min loss 4.921496e-01, std loss 3.615252e-03\n",
      "Epoch 95/100 - mean loss 5.028499e-01, max loss 5.106516e-01, min loss 4.919372e-01, std loss 3.632378e-03\n",
      "Epoch 96/100 - mean loss 5.027820e-01, max loss 5.105646e-01, min loss 4.918746e-01, std loss 3.640399e-03\n",
      "Epoch 97/100 - mean loss 5.027503e-01, max loss 5.104520e-01, min loss 4.918233e-01, std loss 3.627118e-03\n",
      "Epoch 98/100 - mean loss 5.026355e-01, max loss 5.103021e-01, min loss 4.918412e-01, std loss 3.625485e-03\n",
      "Epoch 99/100 - mean loss 5.024950e-01, max loss 5.101384e-01, min loss 4.916374e-01, std loss 3.654039e-03\n",
      "Epoch 100/100 - mean loss 5.021999e-01, max loss 5.100474e-01, min loss 4.916310e-01, std loss 3.623736e-03\n",
      "Elapsed time  0:12:54.399225\n"
     ]
    }
   ],
   "source": [
    "opt_type = 'ADAM'\n",
    "\n",
    "if opt_type == 'ADAM':\n",
    "    \n",
    "    \n",
    "    n_batches = 100\n",
    "    n_points = 4000000\n",
    "    n_points_batch = n_points//n_batches\n",
    "    \n",
    "    lr_opti = optimizers.piecewise_constant([2000,3000,4000,5000,7000], [0.005, 0.005/2, 0.005/4, 0.005/8,0.005/16,0.005/32])\n",
    "    lr_opti = optimizers.piecewise_constant([20,40,60, 80], [0.01, 0.01/2, 0.01/4,0.01/8,0.01/16])\n",
    "    #lr_opti = optimizers.piecewise_constant([7000], [0.01/2, 0.001])\n",
    "    #lr_opti = 0.01/2\n",
    "    opt_init, opt_update, get_params = optimizers.adam(lr_opti)\n",
    "\n",
    "    opt_state = opt_init(model.weights)\n",
    "    weights_init = model.weights\n",
    "    \n",
    "    # get initial parameters\n",
    "    params = get_params(opt_state)\n",
    "\n",
    "    loss_grad = jax.jit(lambda ws, pts: (model.loss(ws, pts), jax.grad(model.loss)(ws, pts)), device = dev)\n",
    "\n",
    "    def step(params, opt_state, key, step_no):\n",
    "        # points = model.get_points_MC(5000)\n",
    "\n",
    "        points = model.points_MonteCarlo(n_points_batch, key, [{'patch': 'round_2', 'label': 'ds2', 'axis': 0, 'end': -1, 'n': n_points_batch}, {'patch': 'round_0', 'label': 'ds0', 'axis': 0, 'end': -1, 'n': n_points_batch}])\n",
    "        parameters_space = jax.random.uniform(key, (n_points_batch, 2))*2-1\n",
    "        loss = model.loss(params, points, parameters_space)\n",
    "        grads = jax.grad(model.loss)(params, points, parameters_space)\n",
    "        #loss, grads = loss_grad(params, points)\n",
    "        opt_state = opt_update(step_no, grads, opt_state)\n",
    "\n",
    "        params = get_params(opt_state)\n",
    "        \n",
    "        return params, opt_state, loss\n",
    "\n",
    "    step_compiled = jax.jit(step, device = dev)\n",
    "    step_compiled(params, opt_state, rnd_key, 0)\n",
    "\n",
    "    n_epochs = 100\n",
    "\n",
    "    hist = []\n",
    "    hist_weights = []\n",
    "    \n",
    "    # min_loss = 10000\n",
    "    tme = datetime.datetime.now()\n",
    "    for ep in range(n_epochs):\n",
    "        losses = []\n",
    "        for b in random.sample(range(n_batches), n_batches):\n",
    "         \n",
    "            params, opt_state, loss = step_compiled(params, opt_state, jax.random.PRNGKey(b+0*np.random.randint(100000)), ep)\n",
    "        \n",
    "            #print(\"\\tbatch %d/%d\"%(b+1, n_batches))\n",
    "            hist.append(loss)\n",
    "            losses.append(loss)\n",
    "    \n",
    "        hist_weights.append(params.copy())\n",
    "        print('Epoch %d/%d - mean loss %e, max loss %e, min loss %e, std loss %e'%(ep+1, n_epochs, np.mean(losses), np.max(losses), np.min(losses), np.std(losses)))\n",
    "        \n",
    "    # update params\n",
    "    model.weights = params\n",
    "    weights = params\n",
    "    tme = datetime.datetime.now() - tme\n",
    "    print('Elapsed time ', tme)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x71ab602df670>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.loglog(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot \n",
    "\n",
    "Save the solution as a `.vtk` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(p1, p2, fname):\n",
    "    with jax.disable_jit():\n",
    "        pv_objects = [pinns.extras.plot(geoms[n], {'displacement': lambda y: model.solutions[n](weights, y, np.zeros((y.shape[0], 2)) + np.array([p1, p2]))}, N= 25) for n in geoms]\n",
    "\n",
    "    obj = pv_objects[0]\n",
    "    for i in range(1,len(pv_objects)):\n",
    "        obj = obj.merge(pv_objects[i])\n",
    "    obj.save(fname)\n",
    "    \n",
    "plot(-1.0, -1.0, \"solution_holder_contacts.0.vtk\")\n",
    "plot(-1.0, 1.0, \"solution_holder_contacts.1.vtk\")\n",
    "plot(1.0, -1.0, \"solution_holder_contacts.2.vtk\")\n",
    "plot(1.0, 1.0, \"solution_holder_contacts.3.vtk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for ep in range(n_epochs):\n",
    "#    with jax.disable_jit():\n",
    "#        pv_objects = [pinns.extras.plot(geoms[n], {'displacement': lambda y: model.solutions[n](hist_weights[ep], y, np.zeros((y.shape[0], 2)))}, N= 25) for n in geoms]\n",
    "#\n",
    "#    obj = pv_objects[0]\n",
    "#    for i in range(1,len(pv_objects)):\n",
    "#        obj = obj.merge(pv_objects[i])\n",
    "#    obj.save('solution_holder_contacts_%d.vtk'%(ep+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "plt = pv.Plotter()\n",
    "\n",
    "p1 = 0.0\n",
    "p2 = 0.0\n",
    "def update_mesh(param, value):\n",
    "    print(value)\n",
    "    global p1, p2\n",
    "    if param==0:\n",
    "        p1 = value\n",
    "    else:\n",
    "        p2 = value\n",
    "    pv_objects = [pinns.extras.plot(geoms[n], {'displacement': lambda y: model.solutions[n](hist_weights[ep], y, np.zeros((y.shape[0], 2))+[p1,p2])}, N= 25) for n in geoms]\n",
    "    obj = pv_objects[0]\n",
    "    for i in range(1,len(pv_objects)):\n",
    "        obj = obj.merge(pv_objects[i])\n",
    "        \n",
    "    plt.add_mesh(pv_objects)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "plt.add_slider_widget(lambda v: update_mesh(0, v), [-1, 1], title='Param 1')\n",
    "plt.add_slider_widget(lambda v: update_mesh(1, v), [-1, 1], title='Param 2')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
